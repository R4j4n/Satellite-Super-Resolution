{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import vgg19\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams \n",
    "class Hyperparameters(object):\n",
    "      def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "hp = Hyperparameters(\n",
    "    dataset_path = \"data/Train/images_png\", \n",
    "    n_epochs = 100 , \n",
    "    batch_size = 8 , \n",
    "    learning_rate =  0.00008, \n",
    "    n_cpu = 4, \n",
    "    height = 512, # image height \n",
    "    width = 512, # image width \n",
    "    channels = 3, # num of channels in images \n",
    "    b1 = 0.5,   # adam: decay of first order momentum of gradient\n",
    "    b2 = 0.999, # adam: decay of second order momentum of gradient\n",
    "    decay_epoch = 100 ,  # epoch from which to start lr decay\n",
    "    cuda = torch.cuda.is_available(), \n",
    "    limit = 10000,\n",
    "    device = \"cuda:0\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std  = np.array([0.229, 0.224, 0.225])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CelebDataset(Dataset):\n",
    "\n",
    "    def __init__(self,paths) -> None:\n",
    "        super().__init__()\n",
    "   \n",
    "        self.items = paths\n",
    "\n",
    "        # transforms for low resolution \n",
    "        self.low_res_transforms = transforms.Compose([\n",
    "            transforms.Resize((hp.height//4, hp.width//4), Image.BICUBIC ), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std= std)\n",
    "        ])\n",
    "        # transforms for high resoultion \n",
    "        self.high_res_transforms = transforms.Compose([\n",
    "            transforms.Resize((hp.height, hp.width), Image.BICUBIC ), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std= std)\n",
    "        ])        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.items[index % len(self.items)]).convert(\"RGB\")\n",
    "        img_lr = self.low_res_transforms(img)\n",
    "        img_hr = self.high_res_transforms(img)\n",
    "\n",
    "        # return {\"lr\": img_lr, \"hr\": img_hr}\n",
    "        return img_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_paths, test_paths = train_test_split(sorted(glob.glob(hp.dataset_path + \"/*.*\"))[:hp.limit], test_size=0.02, random_state=42)\n",
    "train_dataloader = DataLoader(CelebDataset(train_paths), batch_size=hp.batch_size, shuffle=True, num_workers=hp.n_cpu)\n",
    "test_dataloader = DataLoader(CelebDataset(test_paths), batch_size=int(hp.batch_size*0.75), shuffle=True, num_workers=hp.n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images = 0\n",
    "\n",
    "    for images in loader:\n",
    "        image_count_in_a_batch = images.size(0)\n",
    "        images = images.view(image_count_in_a_batch , images.size(1) , -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "        total_images += image_count_in_a_batch\n",
    "    \n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "\n",
    "    return mean , std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = tensor([-0.8496, -0.6413, -0.4793])\n",
      "std = tensor([0.6298, 0.5712, 0.5333])\n"
     ]
    }
   ],
   "source": [
    "mean , std = get_mean_and_std(train_dataloader)\n",
    "print(f\"mean = {mean}\")\n",
    "print(f\"std = {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator and discriminator architecture: \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.residual_block = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size= 3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(in_features),\n",
    "            nn.PReLU(num_parameters= in_features),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size= 3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(in_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return x + self.residual_block(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor) -> None:\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * scale_factor ** 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "        self.act = nn.PReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.act(self.pixel_shuffle(self.conv(x)))\n",
    "    \n",
    "# The Generator     \n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels = 3, out_channels= 3, n_residual_block = 16) :\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv_inp = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,64, kernel_size=9, stride=1, padding=4),\n",
    "                nn.PReLU(num_parameters=64)\n",
    "        )\n",
    "        resblocks = [ResidualBlock(64) for _ in range(n_residual_block)]\n",
    "        self.res_block = nn.Sequential(*resblocks)\n",
    "\n",
    "        self.mid_conv = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64))\n",
    "\n",
    "        self.upsamples = nn.Sequential(\n",
    "            Upsample(64, scale_factor=2),\n",
    "            Upsample(64, scale_factor=2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.final_conv = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh())\n",
    "\n",
    "         \n",
    "\n",
    "    def forward(self,x):\n",
    "        out1 = self.conv_inp(x)\n",
    "        out = self.res_block(out1)\n",
    "        out2 = self.mid_conv(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsamples(out)\n",
    "        out = self.final_conv(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,use_bn = True ,**kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = nn.LeakyReLU(0.2, inplace= True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.act(self.bn(self.cnn(x)))\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                DescConv(\n",
    "                    in_channels,\n",
    "                    feature,\n",
    "                    kernel_size=3,\n",
    "                    stride=1 + idx % 2, # 1,2,1,2,1,2...... \n",
    "                    padding=1,\n",
    "                    use_bn=False if idx == 0 else True,\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*6*6, 1024), # opt from last DescConv block torch.Size([5, 512, 6, 6]) so \n",
    "                                      # 512 * 6 * 6\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VggFeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.feature_extractor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 96, 96])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    low_resolution = 24  # 96x96 -> 24x24\n",
    "    with torch.cuda.amp.autocast():\n",
    "        x = torch.randn((5, 3, low_resolution, low_resolution))\n",
    "        gen = Generator()\n",
    "        gen_out = gen(x)\n",
    "        disc = Discriminator()\n",
    "        disc_out = disc(gen_out)\n",
    "\n",
    "        print(gen_out.shape)\n",
    "        print(disc_out.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/rjn/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:14<00:00, 38.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # models instantiation \n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "feature_extractor = VggFeatureExtractor()\n",
    "feature_extractor.eval()\n",
    "\n",
    "# losses \n",
    "# gan_loss = torch.nn.MSELoss()\n",
    "gan_loss = torch.nn.BCEWithLogitsLoss()\n",
    "content_loss = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "# if hp.cuda:\n",
    "#     generator = generator.cuda()\n",
    "#     discriminator = discriminator.cuda()\n",
    "#     feature_extractor = feature_extractor.cuda()\n",
    "#     gan_loss = gan_loss.cuda()\n",
    "#     content_loss = content_loss.cuda()\n",
    "\n",
    "if hp.cuda:\n",
    "    generator = generator.to(hp.device)\n",
    "    discriminator = discriminator.to(hp.device)\n",
    "    feature_extractor = feature_extractor.to(hp.device)\n",
    "    gan_loss = gan_loss.to(hp.device)\n",
    "    content_loss = content_loss.to(hp.device)\n",
    "\n",
    "\n",
    "# optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=hp.learning_rate, betas=(hp.b1, hp.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=hp.learning_rate, betas=(hp.b1, hp.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if hp.cuda else torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/309 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m\n\u001b[1;32m     18\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#get the inputs\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# low_res_ipt = Variable(imgs['lr'].type(Tensor).to(hp.device))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# high_res_ipt = Variable(imgs['hr'].type(Tensor).to(hp.device))\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m low_res_ipt \u001b[38;5;241m=\u001b[39m \u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(hp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     25\u001b[0m high_res_ipt \u001b[38;5;241m=\u001b[39m imgs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(hp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#################### Generator ######################\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# train losses\n",
    "train_gen_loss, train_disc_loss, train_counter = [], [], []\n",
    "# test losses \n",
    "test_gen_loss, test_disc_loss = [], []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(hp.n_epochs):\n",
    "\n",
    "    ############################ Training ####################\n",
    "    gen_loss = 0\n",
    "    disc_loss = 0\n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Training\")\n",
    "    for batch_idx, imgs in enumerate(train_bar):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        #get the inputs\n",
    "        # low_res_ipt = Variable(imgs['lr'].type(Tensor).to(hp.device))\n",
    "        # high_res_ipt = Variable(imgs['hr'].type(Tensor).to(hp.device))\n",
    "\n",
    "        low_res_ipt = imgs['lr'].to(hp.device)\n",
    "        high_res_ipt = imgs['hr'].to(hp.device)\n",
    "        #################### Generator ######################\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        generated_hr = generator(low_res_ipt)\n",
    "        disc_opt = discriminator(generated_hr)\n",
    "\n",
    "        # Adverserial loss\n",
    "        loss_GAN = gan_loss(disc_opt, torch.ones_like(disc_opt))\n",
    "\n",
    "        # content loss\n",
    "        generated_features = feature_extractor(generated_hr)\n",
    "        real_feaures = feature_extractor(high_res_ipt)\n",
    "        loss_CONTENT = content_loss(generated_features, real_feaures)\n",
    "\n",
    "        # total loss \n",
    "        total_loss_generator = loss_CONTENT + 1e-3 * loss_GAN\n",
    "        \n",
    "        # backpropagate\n",
    "        total_loss_generator.backward()\n",
    "        optimizer_G.step()\n",
    "        #################### discriminator ######################\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_disc_opt = discriminator(high_res_ipt)\n",
    "        loss_D_real = gan_loss(real_disc_opt, torch.ones_like(real_disc_opt))\n",
    "\n",
    "        fake_disc_opt = discriminator(generated_hr.detach())\n",
    "        loss_D_fake = gan_loss(fake_disc_opt, torch.zeros_like(fake_disc_opt))\n",
    "\n",
    "        # total loss \n",
    "        total_disc_loss = (loss_D_real+loss_D_fake) / 2 \n",
    "        \n",
    "        # backprop\n",
    "        total_disc_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        ################## Accumulate losses ###############\n",
    "\n",
    "        gen_loss += total_loss_generator.item()\n",
    "        disc_loss += total_disc_loss.item()\n",
    "\n",
    "        train_bar.set_postfix(\n",
    "            gen_loss = gen_loss/( batch_idx + 1), \n",
    "            disc_loss = disc_loss / (batch_idx + 1 )\n",
    "        )\n",
    "    train_gen_loss.append(gen_loss/len(train_dataloader))\n",
    "    train_disc_loss.append(disc_loss/len(train_dataloader))\n",
    "\n",
    "\n",
    "    ############################ Testing ####################\n",
    "    gen_loss = 0\n",
    "    disc_loss = 0\n",
    "    test_bar = tqdm(test_dataloader,  desc=f\"Testing\")\n",
    "\n",
    "    for batch_idx, imgs in enumerate(test_bar):\n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "\n",
    "        #get the inputs\n",
    "        low_res_ipt = imgs['lr'].to(hp.device)\n",
    "        high_res_ipt = imgs['hr'].to(hp.device)\n",
    "        \n",
    "        ############# Generator Eval ###############\n",
    "\n",
    "        generated_hr = generator(low_res_ipt)\n",
    "        disc_opt = discriminator(generated_hr)\n",
    "\n",
    "        # Adverserial loss\n",
    "        loss_GAN = gan_loss(disc_opt, torch.ones_like(disc_opt))\n",
    "\n",
    "        # content loss\n",
    "        generated_features = feature_extractor(generated_hr)\n",
    "        real_feaures = feature_extractor(high_res_ipt)\n",
    "        loss_CONTENT = content_loss(generated_features, real_feaures)\n",
    "\n",
    "        # total loss \n",
    "        total_loss_generator = loss_CONTENT + 1e-3 * loss_GAN\n",
    "\n",
    "        #################### discriminator eval ######################\n",
    "\n",
    "        real_disc_opt = discriminator(high_res_ipt)\n",
    "        loss_D_real = gan_loss(real_disc_opt, torch.ones_like(real_disc_opt))\n",
    "\n",
    "        fake_disc_opt = discriminator(generated_hr.detach())\n",
    "        loss_D_fake = gan_loss(fake_disc_opt, torch.zeros_like(fake_disc_opt))\n",
    "\n",
    "        # total loss \n",
    "        total_disc_loss = (loss_D_real+loss_D_fake) / 2\n",
    "\n",
    "\n",
    "        ############### Accumulate losses ##########################\n",
    "        gen_loss += total_loss_generator.item()\n",
    "        disc_loss += total_disc_loss.item()\n",
    "\n",
    "        \n",
    "        if random.uniform(0,1)<0.1:\n",
    "\n",
    "            imgs_lr = nn.functional.interpolate(low_res_ipt, scale_factor=4)\n",
    "            imgs_hr = make_grid(high_res_ipt, nrow=1, normalize=True)\n",
    "            gen_hr = make_grid(generated_hr, nrow=1, normalize=True)\n",
    "            imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
    "            img_grid = torch.cat((imgs_hr, imgs_lr, gen_hr), -1)\n",
    "            save_image(img_grid, f\"images/{batch_idx}.png\", normalize=False)\n",
    "\n",
    "\n",
    "        test_bar.set_postfix(\n",
    "            gen_loss = gen_loss/( batch_idx + 1), \n",
    "            disc_loss = disc_loss / (batch_idx + 1 )\n",
    "        )\n",
    "    test_gen_loss.append(gen_loss/len(test_dataloader))\n",
    "    test_disc_loss.append(disc_loss/len(test_dataloader))\n",
    "\n",
    "    torch.save(generator.state_dict(), \"saved_models/generator.pth\")\n",
    "    torch.save(discriminator.state_dict(), \"saved_models/discriminator.pth\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seedformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc4dc57f5c068713ffc7106ef371aff8e2dfb1fc44bc5ef605474acee7c6685e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
