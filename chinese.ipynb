{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import skimage\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = 5 \n",
    "n_epochs = 100 \n",
    "batch_size = 16\n",
    "train_path = 'data/Train/images_png/' \n",
    "val_path = 'data/Train/val_images/' \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "randomcrop = transforms.RandomCrop(128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addGaussNoise(data, sigma):\n",
    "    sigma2 = sigma**2 / (255 ** 2)\n",
    "    noise = random_noise(data, mode='gaussian', var=sigma2, clip=True)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, transform, sigma=30, ex=1):\n",
    "        self.transform = transform\n",
    "        self.sigma = sigma\n",
    "\n",
    "        for _, _, files in os.walk(path):\n",
    "            self.imgs = [path + file for file in files if Image.open(path + file).size >= (96,96)] * ex\n",
    "        np.random.shuffle(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tempImg = self.imgs[index]\n",
    "        tempImg = Image.open(tempImg).convert('RGB') #数据集中有部分图片为灰度图，将所有图片转换为RGB格式\n",
    "        Img = np.array(self.transform(tempImg))/255 #像素归一化至[0,1]\n",
    "        nImg = addGaussNoise(Img, self.sigma) #添加高斯噪声\n",
    "        Img = torch.tensor(Img.transpose(2,0,1)) #由于Image.open加载的图片是H*W*C的格式，因此转换成C*H*W的格式\n",
    "        nImg = torch.tensor(nImg.transpose(2,0,1))\n",
    "        return Img, nImg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, train_path, val_path, transform, sigma, ex=1):\n",
    "    train_dataset = MyDataset(train_path, transform, sigma, ex)\n",
    "    val_dataset = MyDataset(val_path, transform, sigma, ex)\n",
    "    train_iter = DataLoader(train_dataset, batch_size, drop_last=True, num_workers=6)\n",
    "    val_iter = DataLoader(val_dataset, batch_size, drop_last=True, num_workers=6)\n",
    "    return train_iter, val_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = get_data(batch_size, train_path, val_path, randomcrop, 30, ex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inC, outC):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(inC, outC, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                    nn.BatchNorm2d(outC), \n",
    "                                    nn.PReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(outC, outC, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                    nn.BatchNorm2d(outC))\n",
    "\n",
    "    def forward(self, x):\n",
    "        resudial = x\n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out + resudial\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_blocks):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convlayer1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "                                        nn.PReLU())\n",
    "\n",
    "        self.ResBlocks = nn.ModuleList([ResBlock(64, 64) for _ in range(n_blocks)]) #叠加n_blocks个残差块\n",
    "\n",
    "        self.convlayer2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                        nn.BatchNorm2d(64))\n",
    "\n",
    "        self.convout = nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convlayer1(x)\n",
    "        residual = out\n",
    "\n",
    "        for block in self.ResBlocks:\n",
    "            out = block(out)\n",
    "\n",
    "        out = self.convlayer2(out)\n",
    "        out = out + residual\n",
    "\n",
    "        out = self.convout(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel,  stride, kernel_size=3, padding=1):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n",
    "                                   nn.BatchNorm2d(output_channel),\n",
    "                                   nn.LeakyReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "#判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "                                   nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        self.down = nn.Sequential(DownSample(64, 64, stride=2, padding=1),\n",
    "                                  DownSample(64, 128, stride=1, padding=1),\n",
    "                                  DownSample(128, 128, stride=2, padding=1),\n",
    "                                  DownSample(128, 256, stride=1, padding=1),\n",
    "                                  DownSample(256, 256, stride=2, padding=1),\n",
    "                                  DownSample(256, 512, stride=1, padding=1),\n",
    "                                  DownSample(512, 512, stride=2, padding=1))\n",
    "\n",
    "        self.dense = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                   nn.Conv2d(512, 1024, 1),\n",
    "                                   nn.LeakyReLU(inplace=True),\n",
    "                                   nn.Conv2d(1024, 1, 1),\n",
    "                                   nn.Sigmoid()) #Loss为nn.BCELoss则加Sigmoid，若为nn.BCEWithLogitsLoss则不加，因为此Loss里包括了Sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.down(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "#SRGAN使用预训练好的VGG19，用生成器的结果以及原始图像通过VGG后分别得到的特征图计算MSE，具体解释推荐看SRGAN的相关资料\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(VGG, self).__init__()\n",
    "        vgg = models.vgg19(True)\n",
    "        for pa in vgg.parameters():\n",
    "            pa.requires_grad = False\n",
    "        self.vgg = vgg.features[:16]\n",
    "        self.vgg = self.vgg.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.vgg(x)\n",
    "        return out\n",
    "\n",
    "#内容损失\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.vgg19 = VGG(device)\n",
    "\n",
    "    def forward(self, fake, real):\n",
    "        feature_fake = self.vgg19(fake)\n",
    "        feature_real = self.vgg19(real)\n",
    "        loss = self.mse(feature_fake, feature_real)\n",
    "        return loss\n",
    "\n",
    "#对抗损失\n",
    "class AdversarialLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        loss = torch.sum(-torch.log(x))\n",
    "        return loss\n",
    "\n",
    "#感知损失\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.vgg_loss = ContentLoss(device)\n",
    "        self.adversarial = AdversarialLoss()\n",
    "\n",
    "    def forward(self, fake, real, x):\n",
    "        vgg_loss = self.vgg_loss(fake, real)\n",
    "        adversarial_loss = self.adversarial(x)\n",
    "        return vgg_loss + 1e-3*adversarial_loss\n",
    "\n",
    "#正则项，需要说明的是，在SRGAN的后续版本的论文中，这个正则项被删除了\n",
    "class RegularizationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = torch.square(\n",
    "            x[:, :, :x.shape[2]-1, :x.shape[3]-1] - x[:, :, 1:x.shape[2], :x.shape[3]-1]\n",
    "        )\n",
    "        b = torch.square(\n",
    "            x[:, :, :x.shape[2]-1, :x.shape[3]-1] - x[:, :, :x.shape[2]-1, 1:x.shape[3]]\n",
    "        )\n",
    "        loss = torch.sum(torch.pow(a+b, 1.25))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "\n",
    "        self.patience = patience #等待多少个epoch之后停止\n",
    "        self.verbose = verbose #是否显示日志\n",
    "        self.counter = 0 #计步器\n",
    "        self.best_score = None #记录最好性能\n",
    "        self.early_stop = False #早停触发\n",
    "        self.val_psnr_min = 0 #记录最小的验证PSNR\n",
    "        self.delta = delta #可以给最好性能加上的小偏置\n",
    "        self.checkpoint_perf = [] #记录检查点的性能\n",
    "\n",
    "    def __call__(self, g, d, train_psnr, val_psnr):\n",
    "\n",
    "        score = val_psnr\n",
    "        self.early_stop = False\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(g, d, val_psnr)\n",
    "        elif score < self.best_score + self.delta: #PSNR越大越好，因此这里是小于，若使用loss做指标，这里应改成大于\n",
    "            self.counter += 1 #若当前性能不超过前一个epoch的性能则计步器+1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: #计步器累计到达极限，出发早停\n",
    "                self.early_stop = True\n",
    "                self.counter = 0\n",
    "                self.best_score = None\n",
    "                self.val_psnr_min = 0\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(g, d, val_psnr) #保存检查点\n",
    "            self.counter = 0 #计步器重置\n",
    "            self.checkpoint_perf = [train_psnr, val_psnr] #记录检查点性能数据\n",
    "        return self.checkpoint_perf\n",
    "\n",
    "    def save_checkpoint(self, g, d, val_psnr): #保存检查点\n",
    "        self.val_psnr_min = val_psnr\n",
    "        if self.verbose:\n",
    "            print(f'Validation PSNR increased ({self.val_psnr_min:.6f} --> {val_psnr:.6f}).  Saving model ...')\n",
    "            torch.save(g.state_dict(), 'Generator.pth')\n",
    "            torch.save(d.state_dict(), 'Discriminator.pth')\n",
    "        else:\n",
    "            torch.save(g.state_dict(), 'Generator.pth')\n",
    "            torch.save(d.state_dict(), 'Discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjn/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/rjn/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "G = Generator(n_blocks)\n",
    "D = Discriminator()\n",
    "\n",
    "G_loss = PerceptualLoss(device) \n",
    "Regulaztion = RegularizationLoss().to(device)\n",
    "D_loss = nn.BCELoss().to(device)\n",
    "\n",
    "optimizer_g = torch.optim.Adam(G.parameters(), lr=lr*0.1) \n",
    "optimizer_d = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "real_label = torch.ones([batch_size, 1, 1, 1]).to(device)\n",
    "fake_label = torch.zeros([batch_size, 1, 1, 1]).to(device)\n",
    "\n",
    "early_stopping = EarlyStopping(10, verbose=True)\n",
    "\n",
    "#数据记录用\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "train_psnr = []\n",
    "val_loss = []\n",
    "val_psnr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjn/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image, make_grid\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(generator, discriminator, train_iter, val_iter, n_epochs, optimizer_g, optimizer_d, loss_g, loss_d, Regulaztion, device):\n",
    "    print('train on', device)\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    cuda = next(generator.parameters()).device\n",
    "    for epoch in range(n_epochs):\n",
    "        train_epoch_loss_g = []\n",
    "        train_epoch_loss_d = []\n",
    "        train_epoch_psnr = []\n",
    "        val_epoch_loss = []\n",
    "        val_epoch_psnr = []\n",
    "        start = time.time()\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        \n",
    "        train_bar = tqdm(train_iter, desc=f\"Training Epoch {epoch+1}/{n_epochs}\", postfix={'Loss G': 0.0, 'Loss D': 0.0, 'PSNR': 0.0})\n",
    "        for i, (img, nimg) in enumerate(train_bar):\n",
    "            img, nimg = img.to(cuda).float(), nimg.to(cuda).float()\n",
    "            fakeimg = generator(nimg)\n",
    "            \n",
    "            optimizer_d.zero_grad()\n",
    "            realOut = discriminator(img)\n",
    "            fakeOut = discriminator(fakeimg.detach())\n",
    "            loss_d = D_loss(realOut, real_label) + D_loss(fakeOut, fake_label)\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            optimizer_g.zero_grad()\n",
    "            loss_g = G_loss(fakeimg, img, D(fakeimg)) + 2e-8*Regulaztion(fakeimg)\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "            \n",
    "            train_epoch_loss_d.append(loss_d.item())\n",
    "            train_epoch_loss_g.append(loss_g.item())\n",
    "            train_epoch_psnr.append(calculate_psnr(fakeimg, img).item())\n",
    "            \n",
    "            train_bar.set_postfix({'Loss G': np.mean(train_epoch_loss_g), 'Loss D': np.mean(train_epoch_loss_d), 'PSNR': np.mean(train_epoch_psnr)})\n",
    "        \n",
    "        train_epoch_avg_loss_g = np.mean(train_epoch_loss_g)\n",
    "        train_epoch_avg_loss_d = np.mean(train_epoch_loss_d)\n",
    "        train_epoch_avg_psnr = np.mean(train_epoch_psnr)\n",
    "        train_loss_g.append(train_epoch_avg_loss_g)\n",
    "        train_loss_d.append(train_epoch_avg_loss_d)\n",
    "        train_psnr.append(train_epoch_avg_psnr)\n",
    "        print(f'Epoch {epoch + 1}, Generator Train Loss: {train_epoch_avg_loss_g:.4f}, '\n",
    "              f'Discriminator Train Loss: {train_epoch_avg_loss_d:.4f}, PSNR: {train_epoch_avg_psnr:.4f}')\n",
    "        \n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_iter, desc=f\"Validation Epoch {epoch+1}/{n_epochs}\", postfix={'Val Loss': 0.0, 'PSNR': 0.0})\n",
    "            for i, (img, nimg) in enumerate(val_bar):\n",
    "                img, nimg = img.to(cuda).float(), nimg.to(cuda).float()\n",
    "                fakeimg = generator(nimg)\n",
    "                loss_g = G_loss(fakeimg, img, D(fakeimg)) + 2e-8*Regulaztion(fakeimg)\n",
    "                val_epoch_loss.append(loss_g.item())\n",
    "                val_epoch_psnr.append(calculate_psnr(fakeimg, img).item())\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    if i % 8 == 0:\n",
    "                        imgs_hr = make_grid(img, nrow=1, normalize=True)\n",
    "                        gen_hr = make_grid(fakeimg, nrow=1, normalize=True)\n",
    "                        imgs_lr = make_grid(nimg, nrow=1, normalize=True)\n",
    "                        img_grid = torch.cat((imgs_hr, imgs_lr, gen_hr), -1)\n",
    "                        save_image(img_grid, f\"saved_models/srgan_chinese/images/{i}.png\", normalize=False)\n",
    "\n",
    "                val_bar.set_postfix({'Val Loss': np.mean(val_epoch_loss), 'PSNR': np.mean(val_epoch_psnr)})\n",
    "\n",
    "            val_epoch_avg_loss = np.mean(val_epoch_loss)\n",
    "            val_epoch_avg_psnr = np.mean(val_epoch_psnr)\n",
    "            val_loss.append(val_epoch_avg_loss)\n",
    "            val_psnr.append(val_epoch_avg_psnr)\n",
    "            print(f'Generator Val Loss: {val_epoch_avg_loss:.4f}, PSNR: {val_epoch_avg_psnr:.4f}, Cost: {(time.time() - start):.4f}s')\n",
    "            \n",
    "            checkpoint_perf = early_stopping(generator, discriminator, train_epoch_avg_psnr, val_epoch_avg_psnr)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                print('Final model performance:')\n",
    "                print(f'Train PSNR: {checkpoint_perf[0]}, Val PSNR: {checkpoint_perf[1]}')\n",
    "                break\n",
    "        \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/100: 100%|██████████| 103/103 [02:24<00:00,  1.40s/it, Loss G=2.17, Loss D=0.389, PSNR=10.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Generator Train Loss: 2.1737, Discriminator Train Loss: 0.3890, PSNR: 10.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/100: 100%|██████████| 54/54 [00:21<00:00,  2.54it/s, Val Loss=1.26, PSNR=13.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Val Loss: 1.2627, PSNR: 13.1668, Cost: 165.3336s\n",
      "Validation PSNR increased (13.166799 --> 13.166799).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/100: 100%|██████████| 103/103 [02:24<00:00,  1.40s/it, Loss G=1.15, Loss D=0.679, PSNR=17]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Generator Train Loss: 1.1543, Discriminator Train Loss: 0.6786, PSNR: 16.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/100: 100%|██████████| 54/54 [00:19<00:00,  2.77it/s, Val Loss=1.06, PSNR=21.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Val Loss: 1.0630, PSNR: 21.5815, Cost: 163.8409s\n",
      "Validation PSNR increased (21.581490 --> 21.581490).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/100: 100%|██████████| 103/103 [02:23<00:00,  1.39s/it, Loss G=0.925, Loss D=1.12, PSNR=23.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Generator Train Loss: 0.9251, Discriminator Train Loss: 1.1240, PSNR: 23.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/100: 100%|██████████| 54/54 [00:19<00:00,  2.77it/s, Val Loss=1, PSNR=23.9]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Val Loss: 1.0000, PSNR: 23.9280, Cost: 163.1816s\n",
      "Validation PSNR increased (23.927952 --> 23.927952).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/100:  67%|██████▋   | 69/103 [01:38<00:48,  1.42s/it, Loss G=0.936, Loss D=0.622, PSNR=24.3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRegulaztion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, train_iter, val_iter, n_epochs, optimizer_g, optimizer_d, loss_g, loss_d, Regulaztion, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m loss_g\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     35\u001b[0m optimizer_g\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m train_epoch_loss_d\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss_d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m train_epoch_loss_g\u001b[38;5;241m.\u001b[39mappend(loss_g\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     39\u001b[0m train_epoch_psnr\u001b[38;5;241m.\u001b[39mappend(calculate_psnr(fakeimg, img)\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(G, D, train_iter, val_iter, n_epochs, optimizer_g, optimizer_d, G_loss, D_loss, Regulaztion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_term2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
