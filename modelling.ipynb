{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin \n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# all imports\n",
    "import torch \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# our modules\n",
    "from src.config import cfg, root_path\n",
    "from src.utils import MeanSTDFinder\n",
    "from src.data_loaders import SuperResolutionDataLoader\n",
    "from src.models.srgan import Generator, Discriminator, VggFeatureExtractor\n",
    "\n",
    "\n",
    "# create path for models checkpoint\n",
    "Path(root_path).joinpath(\"saved_models/srgan\").mkdir(exist_ok=True, parents=True)\n",
    "Path(root_path).joinpath(\"saved_models/srgan/images\").mkdir(exist_ok=True, parents=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "c = edict()\n",
    "root_pth = \"/home/rjn/Documents/GitHub/Satellite-Super-Resolution\"\n",
    "c.dataset = edict()\n",
    "c.dataset.images_dir = str(Path(root_pth).joinpath(\"data/Train/images_png\"))\n",
    "\n",
    "\n",
    "# config for dataset scaling\n",
    "c.images = edict()\n",
    "c.images.channels = 3\n",
    "c.images.scale_factor = 4\n",
    "c.images.high_resolution_height = 512\n",
    "c.images.high_resolution_width = 512\n",
    "\n",
    "\n",
    "# dataloder\n",
    "c.dataloader = edict()\n",
    "c.dataloader.batch_size = 32\n",
    "c.dataloader.num_workers = 16\n",
    "\n",
    "\n",
    "c.device = edict()\n",
    "c.device.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# clip\n",
    "c.train = edict()\n",
    "c.train.n_epochs = 100\n",
    "c.train.batch_size = 4\n",
    "c.train.learning_rate = 0.00008\n",
    "c.train.n_cpu = multiprocessing.cpu_count() // 2\n",
    "c.train.b1 = 0.5  # adam: decay of first order momentum of gradient\n",
    "c.train.b2 = 0.999  # adam: decay of second order momentum of gradient\n",
    "c.train.decay_epoch = 100  # epoch from which to start lr decay\n",
    "\n",
    "cfg = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images dataset path \n",
    "images_pth = cfg.dataset.images_dir\n",
    "\n",
    "train_paths, test_paths = train_test_split(\n",
    "    sorted(glob.glob(images_pth + \"/*.*\"))[:500],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# get the mean and std of the dataset \n",
    "# mean_std = MeanSTDFinder(images_dir=images_pth)()\n",
    "mean_std = {'mean': [0.2903465 , 0.31224626, 0.29810828],\n",
    " 'std': [0.1457739 , 0.13011318, 0.12317199]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SuperResolutionDataLoader(Dataset):\n",
    "\n",
    "    def __init__(self, paths, mean, std) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.items = paths\n",
    "\n",
    "        # transforms for low resolution\n",
    "        self.low_res_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    (\n",
    "                        cfg.images.high_resolution_height // 4,\n",
    "                        cfg.images.high_resolution_width // 4,\n",
    "                    ),\n",
    "                    Image.BICUBIC,\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # transforms for high resolution\n",
    "        self.high_res_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    (\n",
    "                        cfg.images.high_resolution_height,\n",
    "                        cfg.images.high_resolution_width,\n",
    "                    ),\n",
    "                    Image.BICUBIC,\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img = Image.open(self.items[index % len(self.items)]).convert(\"RGB\")\n",
    "\n",
    "        img_lr = self.low_res_transforms(img)\n",
    "\n",
    "        img_hr = self.high_res_transforms(img)\n",
    "\n",
    "        return img_hr, img_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_pth = cfg.dataset.images_dir\n",
    "\n",
    "train_paths, test_paths = train_test_split(\n",
    "    sorted(glob.glob(images_pth + \"/*.*\")),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# get the mean and std of the dataset \n",
    "# mean_std = MeanSTDFinder(images_dir=images_pth)()\n",
    "mean_std = {'mean': [0.2903465 , 0.31224626, 0.29810828],\n",
    " 'std': [0.1457739 , 0.13011318, 0.12317199]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(\n",
    "    SuperResolutionDataLoader(train_paths,**mean_std),\n",
    "    batch_size=cfg.train.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.train.n_cpu,\n",
    ")\n",
    "val_iter = DataLoader(\n",
    "    SuperResolutionDataLoader(test_paths,**mean_std),\n",
    "    batch_size=int(cfg.train.batch_size * 0.75),\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.train.n_cpu,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inC, outC):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(inC, outC, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                    nn.BatchNorm2d(outC), \n",
    "                                    nn.PReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(outC, outC, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                    nn.BatchNorm2d(outC))\n",
    "\n",
    "    def forward(self, x):\n",
    "        resudial = x\n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out + resudial\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_blocks):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convlayer1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "                                        nn.PReLU())\n",
    "\n",
    "        self.ResBlocks = nn.ModuleList([ResBlock(64, 64) for _ in range(n_blocks)]) #叠加n_blocks个残差块\n",
    "\n",
    "        self.convlayer2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                        nn.BatchNorm2d(64))\n",
    "\n",
    "        self.convout = nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convlayer1(x)\n",
    "        residual = out\n",
    "\n",
    "        for block in self.ResBlocks:\n",
    "            out = block(out)\n",
    "\n",
    "        out = self.convlayer2(out)\n",
    "        out = out + residual\n",
    "\n",
    "        out = self.convout(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel,  stride, kernel_size=3, padding=1):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n",
    "                                   nn.BatchNorm2d(output_channel),\n",
    "                                   nn.LeakyReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "#判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "                                   nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        self.down = nn.Sequential(DownSample(64, 64, stride=2, padding=1),\n",
    "                                  DownSample(64, 128, stride=1, padding=1),\n",
    "                                  DownSample(128, 128, stride=2, padding=1),\n",
    "                                  DownSample(128, 256, stride=1, padding=1),\n",
    "                                  DownSample(256, 256, stride=2, padding=1),\n",
    "                                  DownSample(256, 512, stride=1, padding=1),\n",
    "                                  DownSample(512, 512, stride=2, padding=1))\n",
    "\n",
    "        self.dense = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                   nn.Conv2d(512, 1024, 1),\n",
    "                                   nn.LeakyReLU(inplace=True),\n",
    "                                   nn.Conv2d(1024, 1, 1),\n",
    "                                   nn.Sigmoid()) #Loss为nn.BCELoss则加Sigmoid，若为nn.BCEWithLogitsLoss则不加，因为此Loss里包括了Sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.down(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "#SRGAN使用预训练好的VGG19，用生成器的结果以及原始图像通过VGG后分别得到的特征图计算MSE，具体解释推荐看SRGAN的相关资料\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(VGG, self).__init__()\n",
    "        vgg = models.vgg19(True)\n",
    "        for pa in vgg.parameters():\n",
    "            pa.requires_grad = False\n",
    "        self.vgg = vgg.features[:16]\n",
    "        self.vgg = self.vgg.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.vgg(x)\n",
    "        return out\n",
    "\n",
    "#内容损失\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.vgg19 = VGG(device)\n",
    "\n",
    "    def forward(self, fake, real):\n",
    "        feature_fake = self.vgg19(fake)\n",
    "        feature_real = self.vgg19(real)\n",
    "        loss = self.mse(feature_fake, feature_real)\n",
    "        return loss\n",
    "\n",
    "#对抗损失\n",
    "class AdversarialLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        loss = torch.sum(-torch.log(x))\n",
    "        return loss\n",
    "\n",
    "#感知损失\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.vgg_loss = ContentLoss(device)\n",
    "        self.adversarial = AdversarialLoss()\n",
    "\n",
    "    def forward(self, fake, real, x):\n",
    "        vgg_loss = self.vgg_loss(fake, real)\n",
    "        adversarial_loss = self.adversarial(x)\n",
    "        return vgg_loss + 1e-3*adversarial_loss\n",
    "\n",
    "#正则项，需要说明的是，在SRGAN的后续版本的论文中，这个正则项被删除了\n",
    "class RegularizationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = torch.square(\n",
    "            x[:, :, :x.shape[2]-1, :x.shape[3]-1] - x[:, :, 1:x.shape[2], :x.shape[3]-1]\n",
    "        )\n",
    "        b = torch.square(\n",
    "            x[:, :, :x.shape[2]-1, :x.shape[3]-1] - x[:, :, :x.shape[2]-1, 1:x.shape[3]]\n",
    "        )\n",
    "        loss = torch.sum(torch.pow(a+b, 1.25))\n",
    "        return loss\n",
    "    \n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "\n",
    "        self.patience = patience #等待多少个epoch之后停止\n",
    "        self.verbose = verbose #是否显示日志\n",
    "        self.counter = 0 #计步器\n",
    "        self.best_score = None #记录最好性能\n",
    "        self.early_stop = False #早停触发\n",
    "        self.val_psnr_min = 0 #记录最小的验证PSNR\n",
    "        self.delta = delta #可以给最好性能加上的小偏置\n",
    "        self.checkpoint_perf = [] #记录检查点的性能\n",
    "\n",
    "    def __call__(self, g, d, train_psnr, val_psnr):\n",
    "\n",
    "        score = val_psnr\n",
    "        self.early_stop = False\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(g, d, val_psnr)\n",
    "        elif score < self.best_score + self.delta: #PSNR越大越好，因此这里是小于，若使用loss做指标，这里应改成大于\n",
    "            self.counter += 1 #若当前性能不超过前一个epoch的性能则计步器+1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: #计步器累计到达极限，出发早停\n",
    "                self.early_stop = True\n",
    "                self.counter = 0\n",
    "                self.best_score = None\n",
    "                self.val_psnr_min = 0\n",
    "        else: #当前性能优于或等于前一个epoch的性能，则更新最佳性能记录\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(g, d, val_psnr) #保存检查点\n",
    "            self.counter = 0 #计步器重置\n",
    "            self.checkpoint_perf = [train_psnr, val_psnr] #记录检查点性能数据\n",
    "        return self.checkpoint_perf\n",
    "\n",
    "    def save_checkpoint(self, g, d, val_psnr): #保存检查点\n",
    "        self.val_psnr_min = val_psnr\n",
    "        if self.verbose:\n",
    "            print(f'Validation PSNR increased ({self.val_psnr_min:.6f} --> {val_psnr:.6f}).  Saving model ...')\n",
    "            torch.save(g.state_dict(), 'Generator.pth')\n",
    "            torch.save(d.state_dict(), 'Discriminator.pth')\n",
    "        else:\n",
    "            torch.save(g.state_dict(), 'Generator.pth')\n",
    "            torch.save(d.state_dict(), 'Discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "n_blocks = 5\n",
    "G = Generator(n_blocks)\n",
    "D = Discriminator()\n",
    "\n",
    "G_loss = PerceptualLoss(cfg.device.device) #自定义的loss函数\n",
    "Regulaztion = RegularizationLoss().to(cfg.device.device) #自定义的loss函数\n",
    "D_loss = nn.BCELoss().to(cfg.device.device)\n",
    "\n",
    "optimizer_g = torch.optim.Adam(G.parameters(), lr=lr*0.1) #先训练判别器，后训练生成器，因此生成器的学习率比判别器小\n",
    "optimizer_d = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "real_label = torch.ones([cfg.train.batch_size, 1, 1, 1]).to(cfg.device.device)\n",
    "fake_label = torch.zeros([cfg.train.batch_size, 1, 1, 1]).to(cfg.device.device)\n",
    "\n",
    "early_stopping = EarlyStopping(10, verbose=True)\n",
    "\n",
    "#数据记录用\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "train_psnr = []\n",
    "val_loss = []\n",
    "val_psnr = []\n",
    "\n",
    "cfg.train.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(generator, discriminator, train_iter, val_iter, n_epochs, optimizer_g, optimizer_d, loss_g, loss_d, Regulaztion, device):\n",
    "    print('train on',device)\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    cuda = next(generator.parameters()).device\n",
    "    for epoch in range(n_epochs):\n",
    "        train_epoch_loss_g = [] #数据记录用\n",
    "        train_epoch_loss_d = []\n",
    "        train_epoch_psnr = []\n",
    "        val_epoch_loss = []\n",
    "        val_epoch_psnr = []\n",
    "        start = time.time() #开始时间\n",
    "        generator.train() #设置为训练模式\n",
    "        discriminator.train()\n",
    "        for i, (img, nimg) in enumerate(train_iter):\n",
    "            img, nimg = img.to(cuda).float(), nimg.to(cuda).float()\n",
    "            fakeimg = generator(nimg) #生成器生成“假”图片，即降噪后的图片\n",
    "            \n",
    "            optimizer_d.zero_grad()\n",
    "            realOut = discriminator(img) #判别器对“真”图片，即原始图片的判断，1为真，0为假\n",
    "            fakeOut = discriminator(fakeimg.detach()) #判别器对“假”图片，即生成器生成的图片的判断，1为真，0为假\n",
    "            loss_d = D_loss(realOut, real_label) + D_loss(fakeOut, fake_label) #判别器的损失\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            optimizer_g.zero_grad()\n",
    "            loss_g = G_loss(fakeimg, img, D(fakeimg)) + 2e-8*Regulaztion(fakeimg) #生成器的损失，这里加了正则项\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "            \n",
    "            train_epoch_loss_d.append(loss_d.item()) #记录判别器损失\n",
    "            train_epoch_loss_g.append(loss_g.item()) #记录生成器损失\n",
    "            train_epoch_psnr.append(calculate_psnr(fakeimg, img).item()) #记录PSNR\n",
    "        train_epoch_avg_loss_g = np.mean(train_epoch_loss_g) #计算一个epoch的平均损失\n",
    "        train_epoch_avg_loss_d = np.mean(train_epoch_loss_d)\n",
    "        train_epoch_avg_psnr = np.mean(train_epoch_psnr) #计算一个epoch的平均PSNR\n",
    "        train_loss_g.append(train_epoch_avg_loss_g) #记录生成器的一个epoch的平均损失\n",
    "        train_loss_d.append(train_epoch_avg_loss_d) #记录判别器的一个epoch的平均损失\n",
    "        train_psnr.append(train_epoch_avg_psnr) #记录一个epoch的平均PSNR\n",
    "        print(f'Epoch {epoch + 1}, Generator Train Loss: {train_epoch_avg_loss_g:.4f}, '\n",
    "              f'Discriminator Train Loss: {train_epoch_avg_loss_d:.4f}, PSNR: {train_epoch_avg_psnr:.4f}') #打印epoch训练结果\n",
    "        generator.eval() #设置为验证模式\n",
    "        discriminator.eval()\n",
    "        with torch.no_grad(): #不需要计算梯度\n",
    "            for i, (img, nimg) in enumerate(val_iter): #验证就是简化版的训练，对照着看下，不赘述了\n",
    "                img, nimg = img.to(cuda).float(), nimg.to(cuda).float()\n",
    "                fakeimg = generator(nimg)\n",
    "                loss_g = G_loss(fakeimg, img, D(fakeimg)) + 2e-8*Regulaztion(fakeimg)\n",
    "                val_epoch_loss.append(loss_g.item())\n",
    "                val_epoch_psnr.append(calculate_psnr(fakeimg, img).item())\n",
    "            val_epoch_avg_loss = np.mean(val_epoch_loss)\n",
    "            val_epoch_avg_psnr = np.mean(val_epoch_psnr)\n",
    "            val_loss.append(val_epoch_avg_loss)\n",
    "            val_psnr.append(val_epoch_avg_psnr)\n",
    "            print(f'Generator Val Loss: {val_epoch_avg_loss:.4f}, PSNR: {val_epoch_avg_psnr:.4f}, Cost: {(time.time()-start):.4f}s')\n",
    "            checkpoint_perf = early_stopping(generator, discriminator, train_epoch_avg_psnr, val_epoch_avg_psnr) #应用早停法，选出PSNR最高的那个\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                print('Final model performance:')\n",
    "                print(f'Train PSNR: {checkpoint_perf[0]}, Val PSNR: {checkpoint_perf[1]}')\n",
    "                break\n",
    "        torch.cuda.empty_cache() #清空显存缓存，可以不加这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (128) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRegulaztion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, train_iter, val_iter, n_epochs, optimizer_g, optimizer_d, loss_g, loss_d, Regulaztion, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m optimizer_d\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m optimizer_g\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m loss_g \u001b[38;5;241m=\u001b[39m \u001b[43mG_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfakeimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfakeimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2e-8\u001b[39m\u001b[38;5;241m*\u001b[39mRegulaztion(fakeimg) \u001b[38;5;66;03m#生成器的损失，这里加了正则项\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss_g\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer_g\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m, in \u001b[0;36mPerceptualLoss.forward\u001b[0;34m(self, fake, real, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, fake, real, x):\n\u001b[0;32m---> 49\u001b[0m     vgg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     adversarial_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madversarial(x)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vgg_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\u001b[38;5;241m*\u001b[39madversarial_loss\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mContentLoss.forward\u001b[0;34m(self, fake, real)\u001b[0m\n\u001b[1;32m     27\u001b[0m feature_fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvgg19(fake)\n\u001b[1;32m     28\u001b[0m feature_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvgg19(real)\n\u001b[0;32m---> 29\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_fake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/functional.py:3365\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3363\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3365\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (128) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "train(G, D, train_iter, val_iter, cfg.train.n_epochs, optimizer_g, optimizer_d, G_loss, D_loss, Regulaztion, cfg.device.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_term2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
