{"cells":[{"cell_type":"markdown","metadata":{},"source":["<div style=\"background-color:#5D73F2; color:#19180F; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> SRGAN </div>\n","<div style=\"background-color:#A8B4F6; color:#19180F; font-size:30px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> Architecture Overview</div>\n","<div style=\"background-color:#D5D9F2; color:#19180F; font-size:15px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> \n","The block diagram represents the architecture of SRGAN (Super-Resolution Generative Adversarial Network)<br><br>\n","1. <b>Generator</b> The generator takes a low-resolution image (LR) as input and aims to produce a high-resolution super-resolution image (SR). It consists of several layers, including convolutional layers (conv1, conv2, conv3) and residual blocks (rb1, rb2), which help in extracting features and preserving important details from the LR image. The generator also includes upsampling layers (up1, up2) that upscale the LR image to enhance its resolution. Additional layers (add1, add2) further refine the generated image.<br><br>\n","2. <b>Discriminator</b> The discriminator is responsible for distinguishing between real high-resolution images and generated super-resolution images. It takes the SR image as input (input_disc) and produces a discriminator output, indicating the authenticity of the input image. The discriminator comprises convolutional layers (conv1_disc, conv2_disc, conv3_disc) that extract features from the input image. Additional layers (add1_disc, add2_disc) refine the extracted features and contribute to the discriminator's decision-making process.<br><br>\n","3. <b>Perceptual Loss</b> Perceptual loss in SRGAN combines adversarial loss and content loss to guide the training process. Adversarial loss (adv_loss) encourages the generator to produce SR images that the discriminator cannot distinguish from real HR images. Content loss (content_loss) measures the similarity between the generated SR image and the corresponding ground truth high-resolution image. The combination of these losses helps improve the perceptual quality of the generated images.<br><br>\n","4. <b>Connections</b> The SR image generated by the generator is fed as input to both the discriminator and the perceptual loss. The connection from the generator's output to the discriminator (output -> input_disc) enables the discriminator to classify the generated SR image. The connection from the generator's output to the perceptual loss (output -> adv_loss) uses the SR image to calculate the adversarial loss. Simultaneously, the low-resolution input image (LR) is connected to the perceptual loss (input -> content_loss) to calculate the content loss by comparing it to the ground truth high-resolution image.<br><br>\n","The block diagram provides an overview of how the generator, discriminator, and perceptual loss components interact in the SRGAN architecture to achieve high-quality super-resolution image generation.</div>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:35.255695Z","iopub.status.busy":"2023-07-18T20:37:35.254659Z","iopub.status.idle":"2023-07-18T20:37:35.311161Z","shell.execute_reply":"2023-07-18T20:37:35.310002Z","shell.execute_reply.started":"2023-07-18T20:37:35.255635Z"},"trusted":true},"outputs":[],"source":["# from IPython.display import SVG, display\n","# svg_file = '/kaggle/input/machine-learning-architecture-diagrams/SRGAN.svg'\n","# display(SVG(filename=svg_file))"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Importing modules\n","    </div>\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:41.460072Z","iopub.status.busy":"2023-07-18T20:37:41.459139Z","iopub.status.idle":"2023-07-18T20:37:44.204621Z","shell.execute_reply":"2023-07-18T20:37:44.203550Z","shell.execute_reply.started":"2023-07-18T20:37:41.460018Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader,Dataset\n","import torch.optim as optim\n","from torchvision.models.vgg import vgg19\n","from math import exp\n","import torch\n","import torch.nn.functional as F\n","import torchvision.utils as utils\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import math\n","import pandas as pd\n","import os\n","from os import listdir\n","import numpy as np\n","from PIL import Image\n","from os.path import join"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Setting device    </div>\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.207542Z","iopub.status.busy":"2023-07-18T20:37:44.206880Z","iopub.status.idle":"2023-07-18T20:37:44.273083Z","shell.execute_reply":"2023-07-18T20:37:44.271882Z","shell.execute_reply.started":"2023-07-18T20:37:44.207500Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining hyperparams    </div>\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.276026Z","iopub.status.busy":"2023-07-18T20:37:44.275006Z","iopub.status.idle":"2023-07-18T20:37:44.290288Z","shell.execute_reply":"2023-07-18T20:37:44.288976Z","shell.execute_reply.started":"2023-07-18T20:37:44.275983Z"},"trusted":true},"outputs":[],"source":["upscale_factor = 8\n","crop_size= 88\n","num_epochs= 10"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining mean and standard deviation    </div>\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.295056Z","iopub.status.busy":"2023-07-18T20:37:44.293853Z","iopub.status.idle":"2023-07-18T20:37:44.302007Z","shell.execute_reply":"2023-07-18T20:37:44.301173Z","shell.execute_reply.started":"2023-07-18T20:37:44.295016Z"},"trusted":true},"outputs":[],"source":["mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining helper utility functions    </div>\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from src.data_loaders import SuperResolutionDataLoader\n","from src.config import cfg, root_path\n","import glob\n","from sklearn.model_selection import train_test_split\n","\n","images_pth = cfg.dataset.images_dir\n","\n","train_paths, test_paths = train_test_split(\n","    sorted(glob.glob(images_pth + \"/*.*\"))[:500],\n","    test_size=0.2,\n","    random_state=42,\n",")\n","\n","mean_std = {'mean': [0.2903465 , 0.31224626, 0.29810828],\n"," 'std': [0.1457739 , 0.13011318, 0.12317199]}\n","\n","# load the dataloaders\n","train_loader = DataLoader(\n","    SuperResolutionDataLoader(train_paths,**mean_std),\n","    batch_size=cfg.train.batch_size,\n","    shuffle=True,\n","    num_workers=cfg.train.n_cpu,\n",")\n","val_loader = DataLoader(\n","    SuperResolutionDataLoader(test_paths,**mean_std),\n","    batch_size=int(cfg.train.batch_size * 0.75),\n","    shuffle=True,\n","    num_workers=cfg.train.n_cpu,\n",")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Performing sanity check of the dataloader    </div>\n"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2023-07-18T20:37:44.698955Z","iopub.status.busy":"2023-07-18T20:37:44.698222Z","iopub.status.idle":"2023-07-18T20:38:27.833025Z","shell.execute_reply":"2023-07-18T20:38:27.831345Z","shell.execute_reply.started":"2023-07-18T20:37:44.698898Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([[[[-0.3508, -0.7274, -1.0771,  ...,  1.5055,  0.8867,  0.9405],\n","          [ 0.5101, -0.5122, -1.1309,  ...,  0.9405,  0.0528, -0.1624],\n","          [ 0.8867, -0.5660, -0.9426,  ...,  0.5908, -0.1893, -0.5391],\n","          ...,\n","          [ 0.4294,  0.8598,  0.6177,  ..., -0.5391, -0.5122, -0.1893],\n","          [ 0.5370,  0.6177,  0.8329,  ..., -0.7274, -0.9426, -0.7812],\n","          [ 0.6446,  0.8867,  0.7791,  ..., -0.5391, -1.0771, -0.9964]],\n","\n","         [[-0.3804, -0.7120, -1.1339,  ...,  1.8800,  0.8251,  0.7347],\n","          [ 0.6142, -0.6818, -1.2846,  ...,  1.3375, -0.1393, -0.3202],\n","          [ 0.7046, -0.9531, -1.1942,  ...,  1.3074, -0.0188, -0.4709],\n","          ...,\n","          [ 0.5840,  1.2471,  0.4333,  ..., -0.3202,  0.1922,  0.8553],\n","          [ 0.5840,  0.4333,  0.4032,  ..., -0.5613, -0.5311, -0.4106],\n","          [ 0.4635,  0.3429,  0.2826,  ..., -0.3804, -0.9531, -0.8325]],\n","\n","         [[-0.2234, -0.4781, -0.5100,  ...,  1.6232,  0.7636,  0.6999],\n","          [ 0.6362, -0.5100, -0.7328,  ...,  1.1775, -0.0642, -0.3189],\n","          [ 0.9864, -0.6055, -0.6055,  ...,  0.8591, -0.1598, -0.5418],\n","          ...,\n","          [ 0.0631,  0.5407,  0.2541,  ..., -0.4781, -0.3826,  0.1586],\n","          [ 0.1586,  0.2223,  0.7954,  ..., -0.6055, -0.5736, -0.4463],\n","          [ 0.0950,  0.4133,  0.6044,  ..., -0.1598, -0.7010, -0.7010]]],\n","\n","\n","        [[[ 0.4294,  0.4563,  0.7522,  ...,  0.8060,  0.7791,  0.8060],\n","          [ 0.6715,  0.5101,  0.6446,  ...,  0.6984,  0.5639,  0.6715],\n","          [ 0.8329,  1.0750,  1.0212,  ...,  0.3756,  0.1604,  0.3487],\n","          ...,\n","          [-1.1578, -1.1040, -1.1040,  ...,  2.9851,  1.5862,  1.4517],\n","          [-1.1847, -1.2116, -1.1578,  ...,  3.2272,  1.6669,  1.1019],\n","          [-1.1040, -1.1578, -1.1309,  ...,  3.3348,  1.9628,  1.4248]],\n","\n","         [[ 0.1018,  0.1018,  0.4635,  ...,  1.0361,  0.9156,  1.0663],\n","          [ 0.5539,  0.2525,  0.3429,  ...,  0.9156,  0.7046,  0.8553],\n","          [ 0.5539,  0.7950,  0.6443,  ...,  0.7046,  0.3429,  0.5237],\n","          ...,\n","          [-0.9531, -0.9230, -0.8928,  ...,  3.5076,  1.3978,  1.2471],\n","          [-0.9531, -0.9832, -0.9230,  ...,  3.7487,  1.5184,  0.7649],\n","          [-0.8627, -0.9832, -1.0134,  ...,  3.8994,  2.0910,  1.2471]],\n","\n","         [[ 0.0950,  0.1268,  0.4452,  ...,  0.5407,  0.4452,  0.5088],\n","          [ 0.3497, -0.0324,  0.0631,  ...,  0.7954,  0.4452,  0.3815],\n","          [ 0.3497,  0.6362,  0.5088,  ...,  0.5088,  0.2223,  0.1586],\n","          ...,\n","          [-0.9557, -0.8602, -0.8284,  ...,  3.3424,  0.7954,  1.1456],\n","          [-0.8284, -0.9239, -0.7328,  ...,  3.6290,  0.9864,  0.4770],\n","          [-0.8920, -1.0831, -0.7328,  ...,  3.8200,  1.7187,  0.9546]]]]), tensor([[[[-0.5122, -0.9695, -0.9695,  ...,  0.0259,  0.2680,  0.2411],\n","          [-0.1355, -0.8081, -0.6198,  ...,  0.2680,  0.5370, -0.1355],\n","          [-0.7005, -0.7812, -0.7812,  ...,  0.6177,  1.3172,  0.9674],\n","          ...,\n","          [ 0.2142,  0.8598,  1.6131,  ..., -0.7005, -0.5660, -0.2970],\n","          [ 0.2142,  0.8867,  0.2949,  ..., -0.5660, -0.5391, -0.5929],\n","          [ 0.7522,  0.9943, -0.1086,  ..., -0.7543, -0.3777, -0.5122]],\n","\n","         [[-0.6818, -1.1038, -1.0737,  ...,  0.5237,  0.9758,  0.5237],\n","          [-0.2297, -0.8928, -0.5613,  ...,  0.4032,  0.9457,  0.1922],\n","          [-0.7723, -0.8928, -0.7723,  ...,  1.0964,  1.2471,  0.8854],\n","          ...,\n","          [ 0.3429,  0.5840,  1.1567,  ..., -0.7120, -0.4407,  0.1922],\n","          [ 0.4936,  0.5237,  0.2223,  ..., -0.4709, -0.4106, -0.4106],\n","          [ 0.5237,  0.4936,  0.2826,  ..., -0.8024, -0.2297, -0.1393]],\n","\n","         [[-0.3508, -0.5736, -0.4781,  ...,  0.1905,  0.3497,  0.3178],\n","          [-0.0961, -0.5100, -0.3189,  ...,  0.2860,  0.6044,  0.0631],\n","          [-0.4145, -0.4781, -0.4145,  ...,  0.6362,  1.2411,  0.9546],\n","          ...,\n","          [ 0.4133,  0.5725,  1.3685,  ..., -0.4463, -0.3508, -0.1598],\n","          [ 0.3497,  0.4770,  0.1905,  ..., -0.3189, -0.3826, -0.3826],\n","          [ 0.3497,  0.5088,  0.0313,  ..., -0.4463, -0.1916, -0.2553]]],\n","\n","\n","        [[[ 0.8867,  0.9674,  0.4832,  ..., -0.1086,  0.4563,  0.4832],\n","          [ 1.1557,  0.9674,  0.7253,  ..., -0.6467,  0.4025,  0.1066],\n","          [ 0.4832,  0.6984,  1.1288,  ..., -0.3777,  0.4832, -0.2970],\n","          ...,\n","          [ 2.2318,  1.6400,  0.7253,  ...,  0.4832,  2.9044,  1.2633],\n","          [ 0.6446,  1.5862,  1.9897,  ...,  0.5908,  2.7160,  1.9897],\n","          [-1.3999, -0.3508,  0.1873,  ...,  0.4832,  2.2587,  2.5815]],\n","\n","         [[ 0.5840,  0.7347,  0.3128,  ..., -0.0791,  0.4936,  0.6744],\n","          [ 0.8854,  0.7649,  0.5539,  ..., -0.5914,  0.3730,  0.2826],\n","          [ 0.3128,  0.4333,  0.8251,  ..., -0.3503,  0.5840,  0.0114],\n","          ...,\n","          [ 2.8445,  2.0307,  0.5237,  ...,  0.4635,  3.2363,  1.1567],\n","          [ 1.0663,  2.1814,  2.5431,  ...,  0.4635,  2.9952,  2.0006],\n","          [-1.2244, -0.1996,  0.5237,  ...,  0.2223,  2.4527,  2.8144]],\n","\n","         [[ 0.4133,  0.4133,  0.0631,  ...,  0.1905,  0.4133,  0.3815],\n","          [ 0.6044,  0.4770,  0.2860,  ..., -0.2553,  0.3497,  0.2223],\n","          [ 0.2223,  0.2541,  0.5407,  ..., -0.1279,  0.4133, -0.0324],\n","          ...,\n","          [ 3.0559,  2.1008,  0.4770,  ...,  0.5725,  3.0877,  1.1138],\n","          [ 1.3366,  2.4191,  2.6738,  ...,  0.6044,  2.8649,  1.8142],\n","          [-1.1467, -0.0961,  0.5407,  ...,  0.4133,  2.3555,  2.5783]]]])]\n"]}],"source":["for batch in train_loader:\n","  print(batch)\n","  break"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining residual block    </div>\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.840243Z","iopub.status.busy":"2023-07-18T20:38:27.839496Z","iopub.status.idle":"2023-07-18T20:38:27.850054Z","shell.execute_reply":"2023-07-18T20:38:27.848727Z","shell.execute_reply.started":"2023-07-18T20:38:27.840191Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","  def __init__(self, channels):\n","    super(ResidualBlock, self).__init__()\n","    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn1 = nn.BatchNorm2d(channels)\n","    self.prelu = nn.PReLU()\n","    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn2 = nn.BatchNorm2d(channels)\n","  def forward(self, x):\n","    residual = self.conv1(x)\n","    residual = self.bn1(residual)\n","    residual = self.prelu(residual)\n","    residual = self.conv2(residual)\n","    residual = self.bn2(residual)\n","    return x + residual"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining upsample block    </div>\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.852821Z","iopub.status.busy":"2023-07-18T20:38:27.851887Z","iopub.status.idle":"2023-07-18T20:38:27.864422Z","shell.execute_reply":"2023-07-18T20:38:27.863292Z","shell.execute_reply.started":"2023-07-18T20:38:27.852780Z"},"trusted":true},"outputs":[],"source":["class UpsampleBlock(nn.Module):\n","  def __init__(self, in_channels, up_scale):\n","    super(UpsampleBlock, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, \n","                          kernel_size=3, padding=1)\n","    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n","    self.prelu = nn.PReLU()\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.pixel_shuffle(x)\n","    x = self.prelu(x)\n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining Generator block    </div>\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.867158Z","iopub.status.busy":"2023-07-18T20:38:27.866209Z","iopub.status.idle":"2023-07-18T20:38:27.883617Z","shell.execute_reply":"2023-07-18T20:38:27.882571Z","shell.execute_reply.started":"2023-07-18T20:38:27.867069Z"},"trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","  def __init__(self, scale_factor):\n","    super(Generator, self).__init__()\n","    upsample_block_num = int(math.log(scale_factor, 2))\n","\n","    self.block1 = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n","        nn.PReLU()\n","    )\n","\n","    self.block2 = ResidualBlock(64)\n","    self.block3 = ResidualBlock(64)\n","    self.block4 = ResidualBlock(64)\n","    self.block5 = ResidualBlock(64)\n","    self.block6 = ResidualBlock(64)\n","    self.block7 = nn.Sequential(\n","        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(64)\n","    )\n","    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n","    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n","    self.block8 = nn.Sequential(*block8)\n","  def forward(self, x):\n","    block1 = self.block1(x)\n","    block2 = self.block2(block1)\n","    block3 = self.block3(block2)\n","    block4 = self.block4(block3)\n","    block5 = self.block5(block4)\n","    block6 = self.block6(block5)\n","    block7 = self.block7(block6)\n","    block8 = self.block8(block1 + block7)\n","    return (torch.tanh(block8) + 1) / 2\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining discriminator block    </div>\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.886047Z","iopub.status.busy":"2023-07-18T20:38:27.885044Z","iopub.status.idle":"2023-07-18T20:38:27.905869Z","shell.execute_reply":"2023-07-18T20:38:27.904800Z","shell.execute_reply.started":"2023-07-18T20:38:27.886002Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.net = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.AdaptiveAvgPool2d(1),\n","        nn.Conv2d(512, 1024, kernel_size=1),\n","        nn.LeakyReLU(0.2),\n","        nn.Conv2d(1024, 1, kernel_size=1)\n","    )\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    return torch.sigmoid(self.net(x).view(batch_size))\n","     "]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining TV loss    </div>\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.907977Z","iopub.status.busy":"2023-07-18T20:38:27.907412Z","iopub.status.idle":"2023-07-18T20:38:27.920887Z","shell.execute_reply":"2023-07-18T20:38:27.919691Z","shell.execute_reply.started":"2023-07-18T20:38:27.907917Z"},"trusted":true},"outputs":[],"source":["class TVLoss(nn.Module):\n","  def __init__(self, tv_loss_weight=1):\n","    super(TVLoss, self).__init__()\n","    self.tv_loss_weight=tv_loss_weight\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    h_x = x.size()[2]\n","    w_x = x.size()[3]\n","\n","    count_h = self.tensor_size(x[:, :, 1:, :])\n","    count_w = self.tensor_size(x[:, :, :, 1:])\n","\n","    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n","    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n","    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n","  \n","  @staticmethod \n","  def tensor_size(t):\n","    return t.size()[1] * t.size()[2] * t.size()[3]"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining generator loss    </div>\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.922969Z","iopub.status.busy":"2023-07-18T20:38:27.922490Z","iopub.status.idle":"2023-07-18T20:38:27.933483Z","shell.execute_reply":"2023-07-18T20:38:27.932163Z","shell.execute_reply.started":"2023-07-18T20:38:27.922911Z"},"trusted":true},"outputs":[],"source":["\n","class GeneratorLoss(nn.Module):\n","  def __init__(self):\n","    super(GeneratorLoss, self).__init__()\n","    vgg = vgg19(pretrained=True)\n","    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n","    for param in loss_network.parameters():\n","      param.requires_grad = False\n","    self.loss_network = loss_network\n","    self.mse_loss = nn.MSELoss()\n","    self.tv_loss = TVLoss()\n","  def forward(self, out_labels, out_images, target_images):\n","    adversial_loss = torch.mean(1 - out_labels)\n","    perception_loss = self.mse_loss(out_images, target_images)\n","    image_loss = self.mse_loss(out_images, target_images)\n","    tv_loss = self.tv_loss(out_images)\n","    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Initializing discriminator and generator    </div>\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.935374Z","iopub.status.busy":"2023-07-18T20:38:27.934949Z","iopub.status.idle":"2023-07-18T20:38:28.020191Z","shell.execute_reply":"2023-07-18T20:38:28.019169Z","shell.execute_reply.started":"2023-07-18T20:38:27.935337Z"},"trusted":true},"outputs":[],"source":["netG = Generator(upscale_factor)\n","netD = Discriminator()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:28.022163Z","iopub.status.busy":"2023-07-18T20:38:28.021795Z","iopub.status.idle":"2023-07-18T20:38:33.169683Z","shell.execute_reply":"2023-07-18T20:38:33.168523Z","shell.execute_reply.started":"2023-07-18T20:38:28.022126Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/rjn/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/rjn/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["generator_criterion = GeneratorLoss()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:33.171723Z","iopub.status.busy":"2023-07-18T20:38:33.171246Z","iopub.status.idle":"2023-07-18T20:38:35.896576Z","shell.execute_reply":"2023-07-18T20:38:35.895423Z","shell.execute_reply.started":"2023-07-18T20:38:33.171683Z"},"trusted":true},"outputs":[],"source":["generator_criterion = generator_criterion.to(device)\n","netG = netG.to(device)\n","netD = netD.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining optimizers for generator and discriminator    </div>\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.898866Z","iopub.status.busy":"2023-07-18T20:38:35.898105Z","iopub.status.idle":"2023-07-18T20:38:35.906913Z","shell.execute_reply":"2023-07-18T20:38:35.905841Z","shell.execute_reply.started":"2023-07-18T20:38:35.898820Z"},"trusted":true},"outputs":[],"source":["optimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n","optimizerD = optim.Adam(netD.parameters(), lr=0.0002)\n","     "]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Defining relevant helper functions    </div>\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.909898Z","iopub.status.busy":"2023-07-18T20:38:35.908774Z","iopub.status.idle":"2023-07-18T20:38:35.929474Z","shell.execute_reply":"2023-07-18T20:38:35.928311Z","shell.execute_reply.started":"2023-07-18T20:38:35.909855Z"},"trusted":true},"outputs":[],"source":["def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n","    return gauss / gauss.sum()\n","\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average=True):\n","    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n","\n","    C1 = 0.01 ** 2\n","    C2 = 0.03 ** 2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","def ssim(img1, img2, window_size=11, size_average=True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","\n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","\n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Creating dict to store results    </div>\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.931733Z","iopub.status.busy":"2023-07-18T20:38:35.931181Z","iopub.status.idle":"2023-07-18T20:38:35.944824Z","shell.execute_reply":"2023-07-18T20:38:35.943719Z","shell.execute_reply.started":"2023-07-18T20:38:35.931694Z"},"trusted":true},"outputs":[],"source":["results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","    <b>Remarks</b>    <br>\n","\n","1. Mean square loss is often not great since it compares pixel values, SSIM(Structural similarity) tries to capture the structure of image including noise via statistic. SSIM looks at groups of pixels to decipher whether two images are same or not.<br>\n","2. psnr is peak signal to noise ratio used as yet another metric.<br>\n","3. TV loss obtains better edges by doing total variation(TV) on the reconstructed image and the residual between the reconstructed image and the original image.<br>\n","4. Training model simultaneously.</div>"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Training model for 10 epochs    </div>\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.947173Z","iopub.status.busy":"2023-07-18T20:38:35.946548Z","iopub.status.idle":"2023-07-18T20:53:39.952339Z","shell.execute_reply":"2023-07-18T20:53:39.949248Z","shell.execute_reply.started":"2023-07-18T20:38:35.947130Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/200 [00:01<?, ?it/s]\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 2.00 GiB. GPU ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     20\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 21\u001b[0m fake_img \u001b[38;5;241m=\u001b[39m \u001b[43mnetG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m netD\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m real_out \u001b[38;5;241m=\u001b[39m netD(real_img)\u001b[38;5;241m.\u001b[39mmean()\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m block6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock6(block5)\n\u001b[1;32m     30\u001b[0m block7 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock7(block6)\n\u001b[0;32m---> 31\u001b[0m block8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mblock7\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mtanh(block8) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mUpsampleBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpixel_shuffle(x)\n\u001b[1;32m     11\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprelu(x)\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/nlp_term2/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB. GPU "]}],"source":["for epoch in range(1, num_epochs + 1):\n","        train_bar = tqdm(train_loader)\n","        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n","    \n","        netG.train()\n","        netD.train()\n","        for data, target in train_bar:\n","            g_update_first = True\n","            batch_size = data.size(0)\n","            running_results['batch_sizes'] += batch_size\n","    \n","            ############################\n","            # (1) Update D network: maximize D(x)-1-D(G(z))\n","            ###########################\n","            real_img = Variable(target)\n","            if torch.cuda.is_available():\n","                real_img = real_img.cuda()\n","            z = Variable(data)\n","            if torch.cuda.is_available():\n","                z = z.cuda()\n","            fake_img = netG(z)\n","    \n","            netD.zero_grad()\n","            real_out = netD(real_img).mean()\n","            fake_out = netD(fake_img).mean()\n","            d_loss = 1 - real_out + fake_out\n","            d_loss.backward(retain_graph=True)\n","            optimizerD.step()\n","    \n","            ############################\n","            # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n","            ###########################\n","            netG.zero_grad()\n","            ## The two lines below are added to prevent runetime error in Google Colab ##\n","            fake_img = netG(z)\n","            fake_out = netD(fake_img).mean()\n","            ##\n","            g_loss = generator_criterion(fake_out, fake_img, real_img)\n","            g_loss.backward()\n","            \n","            fake_img = netG(z)\n","            fake_out = netD(fake_img).mean()\n","            \n","            \n","            optimizerG.step()\n","\n","            # loss for current batch before optimization \n","            running_results['g_loss'] += g_loss.item() * batch_size\n","            running_results['d_loss'] += d_loss.item() * batch_size\n","            running_results['d_score'] += real_out.item() * batch_size\n","            running_results['g_score'] += fake_out.item() * batch_size\n","    \n","            train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n","                epoch, num_epochs, running_results['d_loss'] / running_results['batch_sizes'],\n","                running_results['g_loss'] / running_results['batch_sizes'],\n","                running_results['d_score'] / running_results['batch_sizes'],\n","                running_results['g_score'] / running_results['batch_sizes']))\n","    \n","        netG.eval()\n","        \n","        with torch.no_grad():\n","            val_bar = tqdm(val_loader)\n","            valid_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n","            val_images = []\n","            for val_lr, val_hr_restore, val_hr in val_bar:\n","                batch_size = val_lr.size(0)\n","                valid_results['batch_sizes'] += batch_size\n","                lr = val_lr\n","                hr = val_hr\n","                if torch.cuda.is_available():\n","                    lr = lr.cuda()\n","                    hr = hr.cuda()\n","                sr = netG(lr)\n","        \n","                batch_mse = ((sr - hr) ** 2).data.mean()\n","                valid_results['mse'] += batch_mse * batch_size\n","                batch_ssim = ssim(sr, hr).item()\n","                valid_results['ssims'] += batch_ssim * batch_size\n","                valid_results['psnr'] = 10 * math.log10((hr.max()**2) / (valid_results['mse'] / valid_results['batch_sizes']))\n","                valid_results['ssim'] = valid_results['ssims'] / valid_results['batch_sizes']\n","                val_bar.set_description(\n","                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n","                        valid_results['psnr'], valid_results['ssim']))\n","        \n","        if not os.path.exists('epochs/'):\n","          os.makedirs('epochs/')\n","        # save model parameters\n","        if epoch%10==0:\n","          torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (upscale_factor, epoch))\n","          torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (upscale_factor, epoch))\n","        # save loss\\scores\\psnr\\ssim\n","        results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n","        results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n","        results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n","        results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n","        results['psnr'].append(valid_results['psnr'])\n","        results['ssim'].append(valid_results['ssim'])\n","    \n","        if epoch % 10 == 0 and epoch != 0:\n","            out_path = 'statistics/'\n","            if not os.path.exists(out_path):\n","              os.makedirs(out_path)\n","            \n","            data_frame = pd.DataFrame(\n","                data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n","                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n","                index=range(1, epoch + 1))\n","            data_frame.to_csv(out_path + 'srf_' + str(upscale_factor) + '_train_results.csv', index_label='Epoch')\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Evaluating trained model on test image    </div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:55:30.497220Z","iopub.status.busy":"2023-07-18T20:55:30.495966Z","iopub.status.idle":"2023-07-18T20:55:30.561042Z","shell.execute_reply":"2023-07-18T20:55:30.559983Z","shell.execute_reply.started":"2023-07-18T20:55:30.497168Z"},"trusted":true},"outputs":[],"source":["upscale_factor = 8\n","model_name = \"netG_epoch_8_20.pth\"\n","model = Generator(upscale_factor).eval()\n","device=torch.device('gpu')\n","model = model.to(device)\n","model.load_state_dict(torch.load('/kaggle/working/epochs/netG_epoch_8_10.pth'))"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","saving the output and displaying it    </div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:55:31.850697Z","iopub.status.busy":"2023-07-18T20:55:31.850121Z"},"trusted":true},"outputs":[],"source":["# pass any other image, if needed\n","image_name= \"/kaggle/input/div2k-dataset/DIV2K_train_HR/DIV2K_train_HR/0002.png\"\n","image = Image.open(image_name)\n","image = Variable(transforms.ToTensor()(image)).unsqueeze(0).to(device)\n","out = model(image)\n","out_img = transforms.ToPILImage()(out[0].data.cpu())\n","out_img.save('output.jpeg')"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","CUDA memory error   </div>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Verifying the input dimensions to observe the superresolution using SRGAN  </div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(image.shape)\n","print(out_img.shape)"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n","ðŸ“Œ\n","Displaying the input and output images  </div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.imshow(image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.imshow(out_img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
